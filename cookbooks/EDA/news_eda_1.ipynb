{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "import os\n",
    "from src.utils import working_directory_to_src\n",
    "working_directory_to_src()   # run this only once after starting the kernel."
   ],
   "id": "8595f215ebc4a471"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import read_yaml, read_jsonl, remove_outliers\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import timedelta\n",
    "\n",
    "config = read_yaml('config.yaml')\n",
    "config"
   ],
   "id": "6f053308ae0e45d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "list_of_tickers = os.listdir(config[\"NEWS_FOLDER\"])\n",
    "list_of_tickers.sort()\n",
    "number_of_tickers = len(list_of_tickers)\n",
    "print(\"Number of Tickers:\", number_of_tickers)"
   ],
   "id": "cf1937501499a22f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Number of articles per Ticker",
   "id": "9fd2aa1e376220c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ticker_n_articles = {}\n",
    "for ticker in tqdm(list_of_tickers):\n",
    "    data = read_jsonl(os.path.join(config[\"NEWS_FOLDER\"], ticker))\n",
    "    ticker_n_articles[ticker] = len(data)\n"
   ],
   "id": "968e26404f937dc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.boxplot(ticker_n_articles.values())\n",
    "plt.title(\"Number of Articles per Ticker\")\n",
    "plt.show()"
   ],
   "id": "176c9a5528592ac5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.boxplot(remove_outliers(list(ticker_n_articles.values())))\n",
    "plt.title(\"Number of Articles per Ticker (Removing Extreme Outliers)\")\n",
    "plt.show()"
   ],
   "id": "cb47bc6ff208e3b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## K tickers with most and least count",
   "id": "861233010305f2c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_jsonl_from_ticker(ticker):\n",
    "    ticker = ticker.replace(\".jsonl\", '')\n",
    "    return ticker"
   ],
   "id": "e18fd8d7e07b845b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "k = 20\n",
    "ticker_n_articles = dict(sorted(ticker_n_articles.items(), key=lambda item: item[1],  reverse=True))\n",
    "top_k_tickers  = list(ticker_n_articles.keys())[:k]\n",
    "bottom_k_tickers = list(ticker_n_articles.keys())[-k:]\n",
    "# top_k_tickers = [remove_jsonl_from_ticker(ticker) for ticker in top_k_tickers]\n",
    "# bottom_k_tickers = [remove_jsonl_from_ticker(ticker) for ticker in bottom_k_tickers]"
   ],
   "id": "272f7969366d72a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# top K\n",
    "top_k_values= []\n",
    "for ticker in tqdm(top_k_tickers):\n",
    "    top_k_values.append(ticker_n_articles[ticker])\n",
    "\n",
    "plt.barh([remove_jsonl_from_ticker(ticker) for ticker in top_k_tickers], top_k_values)\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Categories\")\n",
    "plt.title(\"Top K\")\n",
    "plt.show()"
   ],
   "id": "79ae2b3e7c40ccdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# bottom K\n",
    "bottom_k_values= []\n",
    "for ticker in tqdm(bottom_k_tickers):\n",
    "    bottom_k_values.append(ticker_n_articles[ticker])\n",
    "\n",
    "plt.barh([remove_jsonl_from_ticker(ticker) for ticker in bottom_k_tickers], bottom_k_values)\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Categories\")\n",
    "plt.title(\"Bottom K\")\n",
    "plt.show()"
   ],
   "id": "bb857535a5c0f9e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## No. of News articles over years for Top K Tickers",
   "id": "e41d9f77f27db65a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_date_n_articles = {\"date\": [], \"ticker\":[]}\n",
    "for ticker in tqdm(top_k_tickers):\n",
    "    ticker_ = remove_jsonl_from_ticker(ticker)\n",
    "    data = read_jsonl(os.path.join(config[\"NEWS_FOLDER\"], ticker))\n",
    "    for article in data:\n",
    "        df_date_n_articles[\"date\"].append(article[\"Date\"])\n",
    "        df_date_n_articles[\"ticker\"].append(ticker_)\n",
    "df_date_n_articles = pd.DataFrame(df_date_n_articles)\n"
   ],
   "id": "620bb107350cc8ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_date_n_articles['date'] = pd.to_datetime(df_date_n_articles['date'])\n",
    "date_counts = (\n",
    "    df_date_n_articles\n",
    "    .groupby(['ticker', 'date'])\n",
    "    .size()\n",
    "    .reset_index(name='freq')\n",
    ")\n",
    "tickers = sorted(date_counts['ticker'].unique())\n",
    "tickers_per_plot = 1\n",
    "n_plots = math.ceil(len(tickers) / tickers_per_plot)\n",
    "for i in range(n_plots):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    batch = tickers[i * tickers_per_plot:(i + 1) * tickers_per_plot]\n",
    "\n",
    "    for ticker in batch:\n",
    "        df_t = date_counts[date_counts['ticker'] == ticker]\n",
    "\n",
    "        plt.plot(\n",
    "            df_t['date'],\n",
    "            df_t['freq'],\n",
    "            marker='o',\n",
    "            label=ticker\n",
    "        )\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Articles')\n",
    "    plt.title(f'Articles per Date')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "a7ffdfba2c96afbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sector Analysis",
   "id": "ffdeeefb916e6d8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_dictionary_df = pd.read_csv(config[\"DATA_DICTIONARY\"])\n",
    "data_dictionary_df[\"Sector\"] = data_dictionary_df[\"Sector\"].fillna(\"N/A\")\n",
    "ticker_to_sector = data_dictionary_df.set_index(\"stock_name\")[\"Sector\"].to_dict()"
   ],
   "id": "c87847ff064de86a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Number of tickers in each sector",
   "id": "ead079d11ada8ec1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sector_counts = Counter(ticker_to_sector.values())\n",
    "plt.bar(sector_counts.keys(),sector_counts.values())\n",
    "plt.xlabel(\"Sector\")\n",
    "plt.ylabel(\"Number of Tickers\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ],
   "id": "2d717bb0dcd35c88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Number of Articles in Each sector",
   "id": "f04853c3ab745a7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "no_of_news_articles_sectors = defaultdict(int)\n",
    "for ticker, n_articles in zip(ticker_n_articles.keys(), ticker_n_articles.values()):\n",
    "    if remove_jsonl_from_ticker(ticker).lower() in ticker_to_sector:\n",
    "        no_of_news_articles_sectors[ticker_to_sector[remove_jsonl_from_ticker(ticker).lower()]] += n_articles\n"
   ],
   "id": "de283e14c58939c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.bar(no_of_news_articles_sectors.keys(),no_of_news_articles_sectors.values())\n",
    "plt.xlabel(\"Sector\")\n",
    "plt.ylabel(\"Number of News Articles\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ],
   "id": "d0487f2a7746b341"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Number of articles over years",
   "id": "29efb5bba32471bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_date_n_articles_sector = {\"date\": [], \"sector\":[]}\n",
    "for ticker in tqdm(list_of_tickers):\n",
    "    ticker_ = remove_jsonl_from_ticker(ticker)\n",
    "    if ticker_.lower() not in ticker_to_sector:\n",
    "        continue\n",
    "    data = read_jsonl(os.path.join(config[\"NEWS_FOLDER\"], ticker))\n",
    "    for article in data:\n",
    "        df_date_n_articles_sector[\"date\"].append(article[\"Date\"])\n",
    "        df_date_n_articles_sector[\"sector\"].append(ticker_to_sector[ticker_.lower()])\n",
    "df_date_n_articles_sector = pd.DataFrame(df_date_n_articles_sector)"
   ],
   "id": "b3a1d4598630e759"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_date_n_articles_sector['date'] = pd.to_datetime(df_date_n_articles_sector['date'])\n",
    "date_counts = (\n",
    "    df_date_n_articles_sector\n",
    "    .groupby(['sector', 'date'])\n",
    "    .size()\n",
    "    .reset_index(name='freq')\n",
    ")\n",
    "sectors = sorted(date_counts['sector'].unique())\n",
    "sectors_per_plot = 1\n",
    "n_plots = math.ceil(len(sectors) / sectors_per_plot)\n",
    "for i in range(n_plots):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    batch = sectors[i * sectors_per_plot:(i + 1) * sectors_per_plot]\n",
    "\n",
    "    for sector in batch:\n",
    "        df_t = date_counts[date_counts['sector'] == sector]\n",
    "\n",
    "        plt.plot(\n",
    "            df_t['date'],\n",
    "            df_t['freq'],\n",
    "            marker='o',\n",
    "            label=sector\n",
    "        )\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Articles')\n",
    "    plt.title(f'Articles per Date')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "8774a705239e69c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Selecting K worthy stokes for model training",
   "id": "fc791024d0655635"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "TOP_K = 20\n",
    "\n",
    "W_MIN = 360*10        # minimum trainable window (days)\n",
    "C_MIN = 0.25       # min coverage inside window\n",
    "G_MAX = 14         # max allowed p90 gap (days)\n",
    "\n",
    "C_TARGET = 0.40\n",
    "G_TARGET = 5\n",
    "G90_TARGET = 14\n",
    "V_TARGET = 1000\n",
    "W_TARGET = 365\n"
   ],
   "id": "80fcc3398d6ccfb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_daily_series(df):\n",
    "    daily = (\n",
    "        df.groupby(\"date\")\n",
    "          .size()\n",
    "          .rename(\"count\")\n",
    "          .to_frame()\n",
    "    )\n",
    "\n",
    "    full_index = pd.date_range(daily.index.min(), daily.index.max(), freq=\"D\")\n",
    "    daily = daily.reindex(full_index, fill_value=0)\n",
    "    daily.index.name = \"date\"\n",
    "    return daily\n"
   ],
   "id": "630c599b2ef72c17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_gap_metrics(active_dates):\n",
    "    if len(active_dates) < 2:\n",
    "        return np.inf, np.inf\n",
    "\n",
    "    gaps = np.diff(active_dates).astype(\"timedelta64[D]\").astype(int)\n",
    "    return gaps.mean(), np.percentile(gaps, 90)\n"
   ],
   "id": "ffee10704f3b565a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_entropy(counts):\n",
    "    probs = counts[counts > 0] / counts.sum()\n",
    "    entropy = -np.sum(probs * np.log(probs))\n",
    "    return entropy / np.log(len(probs)) if len(probs) > 1 else 0.0\n"
   ],
   "id": "254a8367e9e4f604"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_best_window(daily, window_min=W_MIN):\n",
    "    best = None\n",
    "\n",
    "    active_days = daily[daily[\"count\"] > 0]\n",
    "\n",
    "    for start in active_days.index:\n",
    "        end = start + timedelta(days=window_min)\n",
    "\n",
    "        if end > daily.index.max():\n",
    "            break\n",
    "\n",
    "        window = daily.loc[start:end]\n",
    "        coverage = (window[\"count\"] > 0).mean()\n",
    "\n",
    "        active = window[window[\"count\"] > 0]\n",
    "        if len(active) < 2:\n",
    "            continue\n",
    "\n",
    "        avg_gap, p90_gap = compute_gap_metrics(active.index.values)\n",
    "\n",
    "        if coverage >= C_MIN and p90_gap <= G_MAX:\n",
    "            quality = (\n",
    "                0.4 * coverage +\n",
    "                0.3 * (1 - avg_gap / G_MAX) +\n",
    "                0.2 * compute_entropy(window[\"count\"]) +\n",
    "                0.1 * math.log(window[\"count\"].sum() + 1)\n",
    "            )\n",
    "\n",
    "            if best is None or quality > best[\"quality\"]:\n",
    "                best = {\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"quality\": quality,\n",
    "                    \"window_days\": (end - start).days\n",
    "                }\n",
    "\n",
    "    return best\n"
   ],
   "id": "2a4f36c8003a09aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def score_ticker(daily):\n",
    "    total_days = len(daily)\n",
    "    active_days = daily[daily[\"count\"] > 0]\n",
    "\n",
    "    if len(active_days) < 2:\n",
    "        return None\n",
    "\n",
    "    coverage_ratio = len(active_days) / total_days\n",
    "    avg_gap, p90_gap = compute_gap_metrics(active_days.index.values)\n",
    "    entropy = compute_entropy(daily[\"count\"])\n",
    "    total_articles = daily[\"count\"].sum()\n",
    "\n",
    "    window = find_best_window(daily)\n",
    "    if window is None:\n",
    "        return None\n",
    "\n",
    "    # Normalized scores\n",
    "    coverage_score = min(coverage_ratio / C_TARGET, 1)\n",
    "    gap_score = np.exp(-avg_gap / G_TARGET)\n",
    "    p90_gap_score = np.exp(-p90_gap / G90_TARGET)\n",
    "    volume_score = min(np.log(total_articles + 1) / np.log(V_TARGET), 1)\n",
    "    window_score = min(window[\"window_days\"] / W_TARGET, 1)\n",
    "\n",
    "    final_score = (\n",
    "        0.25 * coverage_score +\n",
    "        0.20 * gap_score +\n",
    "        0.15 * p90_gap_score +\n",
    "        0.15 * entropy +\n",
    "        0.15 * volume_score +\n",
    "        0.10 * window_score\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"score\": final_score,\n",
    "        \"coverage\": coverage_ratio,\n",
    "        \"avg_gap\": avg_gap,\n",
    "        \"p90_gap\": p90_gap,\n",
    "        \"entropy\": entropy,\n",
    "        \"total_articles\": total_articles,\n",
    "        \"window\": window\n",
    "    }\n"
   ],
   "id": "2b3132ba852d274b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results = []\n",
    "\n",
    "for ticker in tqdm(list_of_tickers):\n",
    "    data = read_jsonl(os.path.join(config[\"NEWS_FOLDER\"], ticker))\n",
    "    ticker = remove_jsonl_from_ticker(ticker)\n",
    "    records = []\n",
    "    for article in data:\n",
    "        records.append(article[\"Date\"])\n",
    "    df = pd.DataFrame({\"date\": pd.to_datetime(records)})\n",
    "    daily = build_daily_series(df)\n",
    "\n",
    "    metrics = score_ticker(daily)\n",
    "    if metrics:\n",
    "        results.append({\n",
    "            \"ticker\": ticker,\n",
    "            **metrics\n",
    "        })\n"
   ],
   "id": "a1bccd2e388e92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def results_to_dataframe(results):\n",
    "    rows = []\n",
    "\n",
    "    for r in results:\n",
    "        row = {\n",
    "            \"ticker\": r[\"ticker\"],\n",
    "            \"score\": float(r[\"score\"]),\n",
    "            \"coverage\": float(r[\"coverage\"]),\n",
    "            \"avg_gap\": float(r[\"avg_gap\"]),\n",
    "            \"p90_gap\": float(r[\"p90_gap\"]),\n",
    "            \"entropy\": float(r[\"entropy\"]),\n",
    "            \"total_articles\": int(r[\"total_articles\"]),\n",
    "            \"sector\": ticker_to_sector[r[\"ticker\"].lower()] if r[\"ticker\"].lower() in ticker_to_sector else 'N/A',\n",
    "        }\n",
    "\n",
    "        if r.get(\"window\"):\n",
    "            row.update({\n",
    "                \"window_start\": r[\"window\"][\"start\"],\n",
    "                \"window_end\": r[\"window\"][\"end\"],\n",
    "                \"window_days\": int(r[\"window\"][\"window_days\"]),\n",
    "                \"window_quality\": float(r[\"window\"][\"quality\"]),\n",
    "            })\n",
    "        else:\n",
    "            row.update({\n",
    "                \"window_start\": pd.NaT,\n",
    "                \"window_end\": pd.NaT,\n",
    "                \"window_days\": 0,\n",
    "                \"window_quality\": np.nan,\n",
    "            })\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "results_df = results_to_dataframe(results)\n",
    "results_df = results_df.sort_values([\"score\",\"coverage\",\"entropy\"], ascending=False)"
   ],
   "id": "c07c872645d3cfe5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "results_df.to_csv(config[\"STOCK_SCORE_NEWS\"], index=False)",
   "id": "af1521d0a3cfbcf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cee75dc773faac52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
